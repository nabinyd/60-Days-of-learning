{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMehgv0c/nZCdt+g9OSpuVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabinyd/60-Days-of-learning/blob/main/DLPT_08_paper_replicating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 42"
      ],
      "metadata": {
        "id": "6fp6ENEVMjsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Pytorch Paper Replicating\n",
        "\n",
        "The goal of machine learning research paper replicating is: turn a ML research paper into usable code.\n",
        "\n",
        "In this notebook, we're going to be replicating the Vision Transformer."
      ],
      "metadata": {
        "id": "CKqLv0d4M_Ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Get Setup\n",
        "\n",
        "Let's import code we've written + required libraries.\n",
        "\n"
      ],
      "metadata": {
        "id": "FzMYTu7aNnWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "torch.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4rc6G1wbNsJp",
        "outputId": "6985d4ce-4c9d-43f8-9548-6dfc398ae794"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchvision.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BsF-Is0yOSCm",
        "outputId": "645fe5bc-3b3e-4146-ba01-d87e202aa56b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.18.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z48UY_DPEyV",
        "outputId": "27fa7ed4-cb7f-4d00-8705-ddb2100b871a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 35.42 MiB/s, done.\n",
            "Resolving deltas: 100% (2372/2372), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KBJoy4bhPPkm",
        "outputId": "4f487f47-fe1d-400d-999d-cc772d1ae2ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n",
        "\n",
        "The whole goal of what we're trying to do is to replicate the ViT architecture for our FoodVision Mini problem.\n",
        "\n",
        "To do that, we need some data.\n",
        "\n",
        "Namely the pizza, steak and sushi images"
      ],
      "metadata": {
        "id": "elbEQdjUPiBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from GitHub\n",
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwTXhhhYQL6G",
        "outputId": "e6958d7f-2401-45c2-826d-103a9e8acf3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory paths to train and test images\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "tXgh8zv-QSn_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGUxVIhZQrm6",
        "outputId": "eb7e1bdc-9397-4e25-c137-9689afad2731"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "g5z9aOIwQt-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "# Create image size\n",
        "IMAGE_SIZE = 224    # comes from Table od the ViT paper\n",
        "\n",
        "# Create transforms pipeline\n",
        "manual_transforms = transforms.Compose([transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
        "                                        transforms.ToTensor()])\n",
        "\n",
        "print(f\"Manually created tranforms:  {manual_transforms}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2fsNvCfRXOQ",
        "outputId": "01a7c9ef-e822-4051-a2a9-4ef231963af6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually created tranforms:  Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch size of 32\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=manual_transforms,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "len(train_dataloader), len(test_dataloader), class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn-SNxbiSuFE",
        "outputId": "3f194302-cbd2-4836-e190-0b6738b6c16f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 3, ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSbjDwXtTqr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}